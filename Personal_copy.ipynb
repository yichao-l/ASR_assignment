{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASR Assignment 2019-20\n",
    "\n",
    "This notebook has been provided as a template to get you started on the assignment.  Feel free to use it for your development, or do your development directly in Python.\n",
    "\n",
    "You can find a full description of the assignment [here](http://www.inf.ed.ac.uk/teaching/courses/asr/2019-20/coursework.pdf).\n",
    "\n",
    "You are provided with two Python modules `observation_model.py` and `wer.py`.  The first was described in [Lab 3](https://github.com/Ore-an/asr_lab3/blob/master/asr_lab3.ipynb).  The second can be used to compute the number of substitution, deletion and insertion errors between ASR output and a reference text.\n",
    "\n",
    "It can be used as follows:\n",
    "\n",
    "```python\n",
    "import wer\n",
    "\n",
    "my_refence = 'A B C'\n",
    "my_output = 'A C C D'\n",
    "\n",
    "wer.compute_alignment_errors(my_reference, my_output)\n",
    "```\n",
    "\n",
    "This produces a tuple $(s,d,i)$ giving counts of substitution,\n",
    "deletion and insertion errors respectively - in this example (1, 0, 1).  The function accepts either two strings, as in the example above, or two lists.  Matching is case sensitive.\n",
    "\n",
    "## Template code\n",
    "\n",
    "Assuming that you have already made a function to generate an WFST, `create_wfst()` and a decoder class, `MyViterbiDecoder`, you can perform recognition on all the audio files as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import wer\n",
    "import observation_model\n",
    "import openfst_python as fst\n",
    "import time\n",
    "from my_viterbi import *\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c40c162c034d289a95c5e7fba73246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'HEAD_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-24bee990d6fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/asr_labs/ASR_assignment/my_viterbi.py\u001b[0m in \u001b[0;36mrun_exp\u001b[0;34m(num_test)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyViterbiDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwav_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mstate_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbacktrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# you'll need to modify the backtrace() from Lab 4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                                                        \u001b[0;31m# to return the words along the best path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/asr_labs/ASR_assignment/my_viterbi.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraverse_epsilon_arcs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/asr_labs/ASR_assignment/my_viterbi.py\u001b[0m in \u001b[0;36mforward_step\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m    384\u001b[0m                         \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnextstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m                         \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# transition prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m                         \u001b[0mep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_observation_probability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_symbols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0milabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# emission negative log prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m                         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# they're logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/asr_labs/ASR_assignment/observation_model.py\u001b[0m in \u001b[0;36mlog_observation_probability\u001b[0;34m(self, hmm_label, t)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdummy_observation_probability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhmm_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhmm_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdummy_observation_probability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhmm_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'HEAD_1'"
     ]
    }
   ],
   "source": [
    "run_exp(num_test=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def parse_lexicon(lex_file):\n",
    "    \"\"\"\n",
    "    Parse the lexicon file and return it in dictionary form.\n",
    "    \n",
    "    Args:\n",
    "        lex_file (str): filename of lexicon file with structure '<word> <phone1> <phone2>...'\n",
    "                        eg. peppers p eh p er z\n",
    "\n",
    "    Returns:\n",
    "        lex (dict): dictionary mapping words to list of phones\n",
    "    \"\"\"\n",
    "    \n",
    "    lex = {}  # create a dictionary for the lexicon entries (this could be a problem with larger lexica)\n",
    "    with open(lex_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.split()  # split at each space\n",
    "            lex[line[0]] = line[1:]  # first field the word, the rest is the phones\n",
    "    return lex\n",
    "\n",
    "def generate_symbol_tables(lexicon, n=3):\n",
    "    '''\n",
    "    Return word, phone and state symbol tables based on the supplied lexicon\n",
    "        \n",
    "    Args:\n",
    "        lexicon (dict): lexicon to use, created from the parse_lexicon() function\n",
    "        n (int): number of states for each phone HMM\n",
    "        \n",
    "    Returns:\n",
    "        word_table (fst.SymbolTable): table of words\n",
    "        phone_table (fst.SymbolTable): table of phones\n",
    "        state_table (fst.SymbolTable): table of HMM phone-state IDs\n",
    "    '''\n",
    "    \n",
    "    state_table = fst.SymbolTable()\n",
    "    phone_table = fst.SymbolTable()\n",
    "    word_table = fst.SymbolTable()\n",
    "    \n",
    "    # add empty <eps> symbol to all tables\n",
    "    state_table.add_symbol('<eps>')\n",
    "    phone_table.add_symbol('<eps>')\n",
    "    word_table.add_symbol('<eps>')\n",
    "    \n",
    "    for word, phones  in lexicon.items():\n",
    "        \n",
    "        word_table.add_symbol(word)\n",
    "        \n",
    "        for p in phones: # for each phone\n",
    "            \n",
    "            phone_table.add_symbol(p)\n",
    "            for i in range(1,n+1): # for each state 1 to n\n",
    "                state_table.add_symbol('{}_{}'.format(p, i))\n",
    "            \n",
    "    return word_table, phone_table, state_table\n",
    "\n",
    "\n",
    "# call these two functions\n",
    "lex = parse_lexicon('lexicon.txt')\n",
    "word_table, phone_table, state_table = generate_symbol_tables(lex)\n",
    "\n",
    "\n",
    "def generate_phone_wfst(f, start_state, phone, n):\n",
    "    \"\"\"\n",
    "    Generate a WFST representating an n-state left-to-right phone HMM\n",
    "    \n",
    "    Args:\n",
    "        f (fst.Fst()): an FST object, assumed to exist already\n",
    "        start_state (int): the index of the first state, assmed to exist already\n",
    "        phone (str): the phone label \n",
    "        n (int): number of states for each phone HMM\n",
    "        \n",
    "    Returns:\n",
    "        the final state of the FST\n",
    "    \"\"\"\n",
    "    \n",
    "    current_state = start_state\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        \n",
    "        in_label = state_table.find('{}_{}'.format(phone, i))\n",
    "        \n",
    "        sl_weight = fst.Weight('log', -math.log(0.1))  # weight for self-loop\n",
    "        # self-loop back to current state\n",
    "        f.add_arc(current_state, fst.Arc(in_label, 0, sl_weight, current_state))\n",
    "        \n",
    "        # transition to next state\n",
    "        \n",
    "        # we want to output the phone label on the final state\n",
    "        # note: if outputting words instead this code should be modified\n",
    "        if i == n:\n",
    "            out_label = phone_table.find(phone)\n",
    "        else:\n",
    "            out_label = 0   # output empty <eps> label\n",
    "            \n",
    "        next_state = f.add_state()\n",
    "        next_weight = fst.Weight('log', -math.log(0.9)) # weight to next state\n",
    "        f.add_arc(current_state, fst.Arc(in_label, out_label, next_weight, next_state))    \n",
    "       \n",
    "        current_state = next_state\n",
    "        \n",
    "    return current_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.30.1 (20180413.0232)\n",
       " -->\n",
       "<!-- Title: FST Pages: 1 -->\n",
       "<svg width=\"612pt\" height=\"19pt\"\n",
       " viewBox=\"0.00 0.00 612.00 19.45\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(0.234303 0.234303) rotate(0) translate(4 79)\">\n",
       "<title>FST</title>\n",
       "<polygon fill=\"white\" stroke=\"white\" points=\"-4,5 -4,-79 2609,-79 2609,5 -4,5\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" stroke-width=\"2\" cx=\"50\" cy=\"-23\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-19.3\" font-family=\"Times,serif\" font-size=\"14.00\">0</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;0 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M36.7449,-35.5448C30.2965,-46.8696 34.7148,-59 50,-59 60.8668,-59 66.2412,-52.8689 66.1231,-45.255\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"69.4444,-44.1438 63.2551,-35.5448 62.7311,-46.1267 69.4444,-44.1438\"/>\n",
       "<text text-anchor=\"middle\" x=\"50\" y=\"-62.8\" font-family=\"Times,serif\" font-size=\"14.00\">p_1:&lt;eps&gt;/2.3026</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"224\" cy=\"-23\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"224\" y=\"-19.3\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M68.1208,-23C97.9989,-23 159.887,-23 195.726,-23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"195.948,-26.5001 205.948,-23 195.948,-19.5001 195.948,-26.5001\"/>\n",
       "<text text-anchor=\"middle\" x=\"137\" y=\"-26.8\" font-family=\"Times,serif\" font-size=\"14.00\">p_1:&lt;eps&gt;/0.10536</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;1 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>1&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M210.745,-35.5448C204.296,-46.8696 208.715,-59 224,-59 234.867,-59 240.241,-52.8689 240.123,-45.255\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"243.444,-44.1438 237.255,-35.5448 236.731,-46.1267 243.444,-44.1438\"/>\n",
       "<text text-anchor=\"middle\" x=\"224\" y=\"-62.8\" font-family=\"Times,serif\" font-size=\"14.00\">p_2:&lt;eps&gt;/2.3026</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"398\" cy=\"-23\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"398\" y=\"-19.3\" font-family=\"Times,serif\" font-size=\"14.00\">2</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M242.121,-23C271.999,-23 333.887,-23 369.726,-23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"369.948,-26.5001 379.948,-23 369.948,-19.5001 369.948,-26.5001\"/>\n",
       "<text text-anchor=\"middle\" x=\"311\" y=\"-26.8\" font-family=\"Times,serif\" font-size=\"14.00\">p_2:&lt;eps&gt;/0.10536</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;2 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>2&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M386.244,-37.0417C381.847,-47.9126 385.766,-59 398,-59 406.411,-59 410.892,-53.7595 411.442,-46.9516\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"414.884,-46.3132 409.756,-37.0417 407.983,-47.4871 414.884,-46.3132\"/>\n",
       "<text text-anchor=\"middle\" x=\"398\" y=\"-62.8\" font-family=\"Times,serif\" font-size=\"14.00\">p_3:&lt;eps&gt;/2.3026</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"544\" cy=\"-23\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"544\" y=\"-19.3\" font-family=\"Times,serif\" font-size=\"14.00\">3</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M416.084,-23C440.659,-23 486.247,-23 515.573,-23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"515.938,-26.5001 525.938,-23 515.938,-19.5001 515.938,-26.5001\"/>\n",
       "<text text-anchor=\"middle\" x=\"471\" y=\"-26.8\" font-family=\"Times,serif\" font-size=\"14.00\">p_3:p/0.10536</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;3 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>3&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M532.244,-37.0417C527.847,-47.9126 531.766,-59 544,-59 552.411,-59 556.892,-53.7595 557.442,-46.9516\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"560.884,-46.3132 555.756,-37.0417 553.983,-47.4871 560.884,-46.3132\"/>\n",
       "<text text-anchor=\"middle\" x=\"544\" y=\"-62.8\" font-family=\"Times,serif\" font-size=\"14.00\">eh_1:&lt;eps&gt;/2.3026</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"724\" cy=\"-23\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"724\" y=\"-19.3\" font-family=\"Times,serif\" font-size=\"14.00\">4</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;4 -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>3&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M562.067,-23C593.034,-23 658.701,-23 695.871,-23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"695.984,-26.5001 705.984,-23 695.984,-19.5001 695.984,-26.5001\"/>\n",
       "<text text-anchor=\"middle\" x=\"634\" y=\"-26.8\" font-family=\"Times,serif\" font-size=\"14.00\">eh_1:&lt;eps&gt;/0.10536</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;4 -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>4&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M710.355,-35.1718C703.28,-46.6016 707.828,-59 724,-59 735.624,-59 741.242,-52.5949 740.856,-44.7481\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"744.143,-43.54 737.645,-35.1718 737.506,-45.7657 744.143,-43.54\"/>\n",
       "<text text-anchor=\"middle\" x=\"724\" y=\"-62.8\" font-family=\"Times,serif\" font-size=\"14.00\">eh_2:&lt;eps&gt;/2.3026</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"904\" cy=\"-23\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"904\" y=\"-19.3\" font-family=\"Times,serif\" font-size=\"14.00\">5</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge10\" class=\"edge\"><title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M742.067,-23C773.034,-23 838.701,-23 875.871,-23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"875.984,-26.5001 885.984,-23 875.984,-19.5001 875.984,-26.5001\"/>\n",
       "<text text-anchor=\"middle\" x=\"814\" y=\"-26.8\" font-family=\"Times,serif\" font-size=\"14.00\">eh_2:&lt;eps&gt;/0.10536</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;5 -->\n",
       "<g id=\"edge11\" class=\"edge\"><title>5&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M891.607,-36.2925C886.31,-47.397 890.441,-59 904,-59 913.322,-59 918.187,-53.5158 918.597,-46.4797\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"921.928,-45.3266 916.393,-36.2925 915.087,-46.8064 921.928,-45.3266\"/>\n",
       "<text text-anchor=\"middle\" x=\"904\" y=\"-62.8\" font-family=\"Times,serif\" font-size=\"14.00\">eh_3:&lt;eps&gt;/2.3026</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1062\" cy=\"-23\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1062\" y=\"-19.3\" font-family=\"Times,serif\" font-size=\"14.00\">6</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge12\" class=\"edge\"><title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M922.291,-23C949.232,-23 1001.46,-23 1033.58,-23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1033.63,-26.5001 1043.63,-23 1033.63,-19.5001 1033.63,-26.5001\"/>\n",
       "<text text-anchor=\"middle\" x=\"983\" y=\"-26.8\" font-family=\"Times,serif\" font-size=\"14.00\">eh_3:eh/0.10536</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;6 -->\n",
       "<g id=\"edge13\" class=\"edge\"><title>6&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1049.61,-36.2925C1044.31,-47.397 1048.44,-59 1062,-59 1071.32,-59 1076.19,-53.5158 1076.6,-46.4797\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1079.93,-45.3266 1074.39,-36.2925 1073.09,-46.8064 1079.93,-45.3266\"/>\n",
       "<text text-anchor=\"middle\" x=\"1062\" y=\"-62.8\" font-family=\"Times,serif\" font-size=\"14.00\">p_1:&lt;eps&gt;/2.3026</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\"><title>7</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1236\" cy=\"-23\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1236\" y=\"-19.3\" font-family=\"Times,serif\" font-size=\"14.00\">7</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;7 -->\n",
       "<g id=\"edge14\" class=\"edge\"><title>6&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1080.12,-23C1110,-23 1171.89,-23 1207.73,-23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1207.95,-26.5001 1217.95,-23 1207.95,-19.5001 1207.95,-26.5001\"/>\n",
       "<text text-anchor=\"middle\" x=\"1149\" y=\"-26.8\" font-family=\"Times,serif\" font-size=\"14.00\">p_1:&lt;eps&gt;/0.10536</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;7 -->\n",
       "<g id=\"edge15\" class=\"edge\"><title>7&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1222.74,-35.5448C1216.3,-46.8696 1220.71,-59 1236,-59 1246.87,-59 1252.24,-52.8689 1252.12,-45.255\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1255.44,-44.1438 1249.26,-35.5448 1248.73,-46.1267 1255.44,-44.1438\"/>\n",
       "<text text-anchor=\"middle\" x=\"1236\" y=\"-62.8\" font-family=\"Times,serif\" font-size=\"14.00\">p_2:&lt;eps&gt;/2.3026</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\"><title>8</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1410\" cy=\"-23\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1410\" y=\"-19.3\" font-family=\"Times,serif\" font-size=\"14.00\">8</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;8 -->\n",
       "<g id=\"edge16\" class=\"edge\"><title>7&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1254.12,-23C1284,-23 1345.89,-23 1381.73,-23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1381.95,-26.5001 1391.95,-23 1381.95,-19.5001 1381.95,-26.5001\"/>\n",
       "<text text-anchor=\"middle\" x=\"1323\" y=\"-26.8\" font-family=\"Times,serif\" font-size=\"14.00\">p_2:&lt;eps&gt;/0.10536</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;8 -->\n",
       "<g id=\"edge17\" class=\"edge\"><title>8&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1398.24,-37.0417C1393.85,-47.9126 1397.77,-59 1410,-59 1418.41,-59 1422.89,-53.7595 1423.44,-46.9516\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1426.88,-46.3132 1421.76,-37.0417 1419.98,-47.4871 1426.88,-46.3132\"/>\n",
       "<text text-anchor=\"middle\" x=\"1410\" y=\"-62.8\" font-family=\"Times,serif\" font-size=\"14.00\">p_3:&lt;eps&gt;/2.3026</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\"><title>9</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1556\" cy=\"-23\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1556\" y=\"-19.3\" font-family=\"Times,serif\" font-size=\"14.00\">9</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g id=\"edge18\" class=\"edge\"><title>8&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1428.08,-23C1452.66,-23 1498.25,-23 1527.57,-23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1527.94,-26.5001 1537.94,-23 1527.94,-19.5001 1527.94,-26.5001\"/>\n",
       "<text text-anchor=\"middle\" x=\"1483\" y=\"-26.8\" font-family=\"Times,serif\" font-size=\"14.00\">p_3:p/0.10536</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;9 -->\n",
       "<g id=\"edge19\" class=\"edge\"><title>9&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1544.24,-37.0417C1539.85,-47.9126 1543.77,-59 1556,-59 1564.41,-59 1568.89,-53.7595 1569.44,-46.9516\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1572.88,-46.3132 1567.76,-37.0417 1565.98,-47.4871 1572.88,-46.3132\"/>\n",
       "<text text-anchor=\"middle\" x=\"1556\" y=\"-62.8\" font-family=\"Times,serif\" font-size=\"14.00\">er_1:&lt;eps&gt;/2.3026</text>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\"><title>10</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1736\" cy=\"-23\" rx=\"19.4965\" ry=\"19.4965\"/>\n",
       "<text text-anchor=\"middle\" x=\"1736\" y=\"-19.3\" font-family=\"Times,serif\" font-size=\"14.00\">10</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;10 -->\n",
       "<g id=\"edge20\" class=\"edge\"><title>9&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1574.07,-23C1604.56,-23 1668.69,-23 1706.14,-23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1706.39,-26.5001 1716.39,-23 1706.39,-19.5001 1706.39,-26.5001\"/>\n",
       "<text text-anchor=\"middle\" x=\"1645\" y=\"-26.8\" font-family=\"Times,serif\" font-size=\"14.00\">er_1:&lt;eps&gt;/0.10536</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;10 -->\n",
       "<g id=\"edge21\" class=\"edge\"><title>10&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1721.7,-36.6617C1715.59,-48.0747 1720.36,-60 1736,-60 1747.12,-60 1752.75,-53.9726 1752.87,-46.3869\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1756.24,-45.434 1750.3,-36.6617 1749.47,-47.2243 1756.24,-45.434\"/>\n",
       "<text text-anchor=\"middle\" x=\"1736\" y=\"-63.8\" font-family=\"Times,serif\" font-size=\"14.00\">er_2:&lt;eps&gt;/2.3026</text>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\"><title>11</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1918\" cy=\"-23\" rx=\"19.4965\" ry=\"19.4965\"/>\n",
       "<text text-anchor=\"middle\" x=\"1918\" y=\"-19.3\" font-family=\"Times,serif\" font-size=\"14.00\">11</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;11 -->\n",
       "<g id=\"edge22\" class=\"edge\"><title>10&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1755.59,-23C1786.98,-23 1850.73,-23 1888.03,-23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1888.25,-26.5001 1898.25,-23 1888.25,-19.5001 1888.25,-26.5001\"/>\n",
       "<text text-anchor=\"middle\" x=\"1827\" y=\"-26.8\" font-family=\"Times,serif\" font-size=\"14.00\">er_2:&lt;eps&gt;/0.10536</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;11 -->\n",
       "<g id=\"edge23\" class=\"edge\"><title>11&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1905.1,-37.8171C1900.6,-48.8651 1904.9,-60 1918,-60 1927.01,-60 1931.85,-54.737 1932.54,-47.8576\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1935.97,-47.1205 1930.9,-37.8171 1929.06,-48.2512 1935.97,-47.1205\"/>\n",
       "<text text-anchor=\"middle\" x=\"1918\" y=\"-63.8\" font-family=\"Times,serif\" font-size=\"14.00\">er_3:&lt;eps&gt;/2.3026</text>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\"><title>12</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2076\" cy=\"-23\" rx=\"19.4965\" ry=\"19.4965\"/>\n",
       "<text text-anchor=\"middle\" x=\"2076\" y=\"-19.3\" font-family=\"Times,serif\" font-size=\"14.00\">12</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;12 -->\n",
       "<g id=\"edge24\" class=\"edge\"><title>11&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1937.51,-23C1964.34,-23 2014.29,-23 2046.02,-23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2046.03,-26.5001 2056.03,-23 2046.03,-19.5001 2046.03,-26.5001\"/>\n",
       "<text text-anchor=\"middle\" x=\"1997\" y=\"-26.8\" font-family=\"Times,serif\" font-size=\"14.00\">er_3:er/0.10536</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;12 -->\n",
       "<g id=\"edge25\" class=\"edge\"><title>12&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2063.1,-37.8171C2058.6,-48.8651 2062.9,-60 2076,-60 2085.01,-60 2089.85,-54.737 2090.54,-47.8576\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2093.97,-47.1205 2088.9,-37.8171 2087.06,-48.2512 2093.97,-47.1205\"/>\n",
       "<text text-anchor=\"middle\" x=\"2076\" y=\"-63.8\" font-family=\"Times,serif\" font-size=\"14.00\">z_1:&lt;eps&gt;/2.3026</text>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\"><title>13</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2252\" cy=\"-23\" rx=\"19.4965\" ry=\"19.4965\"/>\n",
       "<text text-anchor=\"middle\" x=\"2252\" y=\"-19.3\" font-family=\"Times,serif\" font-size=\"14.00\">13</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;13 -->\n",
       "<g id=\"edge26\" class=\"edge\"><title>12&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2095.62,-23C2125.89,-23 2186,-23 2221.93,-23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2222.25,-26.5001 2232.25,-23 2222.25,-19.5001 2222.25,-26.5001\"/>\n",
       "<text text-anchor=\"middle\" x=\"2164\" y=\"-26.8\" font-family=\"Times,serif\" font-size=\"14.00\">z_1:&lt;eps&gt;/0.10536</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;13 -->\n",
       "<g id=\"edge27\" class=\"edge\"><title>13&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2238.02,-36.6617C2232.04,-48.0747 2236.7,-60 2252,-60 2262.88,-60 2268.37,-53.9726 2268.5,-46.3869\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2271.88,-45.4666 2265.98,-36.6617 2265.1,-47.2196 2271.88,-45.4666\"/>\n",
       "<text text-anchor=\"middle\" x=\"2252\" y=\"-63.8\" font-family=\"Times,serif\" font-size=\"14.00\">z_2:&lt;eps&gt;/2.3026</text>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\"><title>14</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2428\" cy=\"-23\" rx=\"19.4965\" ry=\"19.4965\"/>\n",
       "<text text-anchor=\"middle\" x=\"2428\" y=\"-19.3\" font-family=\"Times,serif\" font-size=\"14.00\">14</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;14 -->\n",
       "<g id=\"edge28\" class=\"edge\"><title>13&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2271.62,-23C2301.89,-23 2362,-23 2397.93,-23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2398.25,-26.5001 2408.25,-23 2398.25,-19.5001 2398.25,-26.5001\"/>\n",
       "<text text-anchor=\"middle\" x=\"2340\" y=\"-26.8\" font-family=\"Times,serif\" font-size=\"14.00\">z_2:&lt;eps&gt;/0.10536</text>\n",
       "</g>\n",
       "<!-- 14&#45;&gt;14 -->\n",
       "<g id=\"edge29\" class=\"edge\"><title>14&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2415.62,-38.2025C2411.59,-49.1225 2415.71,-60 2428,-60 2436.25,-60 2440.83,-55.0897 2441.71,-48.5554\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2445.13,-47.6737 2440.38,-38.2025 2438.19,-48.5677 2445.13,-47.6737\"/>\n",
       "<text text-anchor=\"middle\" x=\"2428\" y=\"-63.8\" font-family=\"Times,serif\" font-size=\"14.00\">z_3:&lt;eps&gt;/2.3026</text>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node16\" class=\"node\"><title>15</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2580\" cy=\"-23\" rx=\"19.4968\" ry=\"19.4968\"/>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2580\" cy=\"-23\" rx=\"23.4965\" ry=\"23.4965\"/>\n",
       "<text text-anchor=\"middle\" x=\"2580\" y=\"-19.3\" font-family=\"Times,serif\" font-size=\"14.00\">15</text>\n",
       "</g>\n",
       "<!-- 14&#45;&gt;15 -->\n",
       "<g id=\"edge30\" class=\"edge\"><title>14&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2447.69,-23C2472.35,-23 2516.15,-23 2546.34,-23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2546.39,-26.5001 2556.39,-23 2546.39,-19.5001 2546.39,-26.5001\"/>\n",
       "<text text-anchor=\"middle\" x=\"2502\" y=\"-26.8\" font-family=\"Times,serif\" font-size=\"14.00\">z_3:z/0.10536</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<vector Fst at 0x7fb71bc86370>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_word_wfst(word):\n",
    "    \"\"\" Generate a WFST for any word in the lexicon, composed of 3-state phone WFSTs.\n",
    "        This will currently output word labels.  \n",
    "        Exercise: could you modify this function and the one above to output a single phone label instead?\n",
    "    \n",
    "    Args:\n",
    "        word (str): the word to generate\n",
    "        \n",
    "    Returns:\n",
    "        the constructed WFST\n",
    "    \n",
    "    \"\"\"\n",
    "    f = fst.Fst('log')\n",
    "    \n",
    "    # create the start state\n",
    "    start_state = f.add_state()\n",
    "    f.set_start(start_state)\n",
    "    \n",
    "    current_state = start_state\n",
    "    \n",
    "    # iterate over all the phones in the word\n",
    "    for phone in lex[word]:   # will raise an exception if word is not in the lexicon\n",
    "        \n",
    "        current_state = generate_phone_wfst(f, current_state, phone, 3)\n",
    "    \n",
    "        # note: new current_state is now set to the final state of the previous phone WFST\n",
    "        \n",
    "    f.set_final(current_state)\n",
    "    \n",
    "    return f\n",
    "\n",
    "f= generate_word_wfst('peppers')\n",
    "f.set_input_symbols(state_table)\n",
    "f.set_output_symbols(phone_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_multiple_words_wfst(word_list):\n",
    "    \"\"\" Generate a WFST for any word in the lexicon, composed of 3-state phone WFSTs.\n",
    "        This will currently output word labels.  \n",
    "        Exercise: could you modify this function and the one above to output a single phone label instead?\n",
    "    \n",
    "    Args:\n",
    "        word (str): the word to generate\n",
    "        \n",
    "    Returns:\n",
    "        the constructed WFST\n",
    "    \n",
    "    \"\"\"\n",
    "    if isinstance(word_list, str):\n",
    "        word_list = word_list.split()\n",
    "    f = fst.Fst(\"log\")\n",
    "    start_state = f.add_state()\n",
    "    f.set_start(start_state)\n",
    "    for word in word_list:\n",
    "        # create the start state\n",
    "        \n",
    "        current_state = f.add_state()\n",
    "        \n",
    "        f.add_arc(start_state, fst.Arc(0, 0, fst.Weight(\"log\",-math.log(1/len(word_list))), current_state))\n",
    "    \n",
    "        # iterate over all the phones in the word\n",
    "        for phone in lex[word]:   # will raise an exception if word is not in the lexicon\n",
    "        \n",
    "            current_state = generate_phone_wfst(f, current_state, phone, 3)\n",
    "            \n",
    "    \n",
    "            # note: new current_state is now set to the final state of the previous phone WFST\n",
    "        \n",
    "        f.add_arc(current_state, fst.Arc(0, 0, fst.Weight(\"log\",-math.log(1)), start_state))\n",
    "    \n",
    "        f.set_final(current_state)\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyViterbiDecoder:\n",
    "    \n",
    "    NLL_ZERO = 1e10  # define a constant representing -log(0).  This is really infinite, but approximate\n",
    "                     # it here with a very large number\n",
    "    \n",
    "    def __init__(self, f, audio_file_name):\n",
    "        \"\"\"Set up the decoder class with an audio file and WFST f\n",
    "        \"\"\"\n",
    "        self.om = observation_model.ObservationModel()\n",
    "        self.f = f\n",
    "        \n",
    "        if audio_file_name:\n",
    "            self.om.load_audio(audio_file_name)\n",
    "        else:\n",
    "            self.om.load_dummy_audio()\n",
    "        \n",
    "        self.initialise_decoding()\n",
    "\n",
    "        \n",
    "    def initialise_decoding(self):\n",
    "        \"\"\"set up the values for V_j(0) (as negative log-likelihoods)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.V = []   # stores likelihood along best path reaching state j\n",
    "        self.B = []   # stores identity of best previous state reaching state j\n",
    "        self.W = []   # stores output labels sequence along arc reaching j - this removes need for \n",
    "                      # extra code to read the output sequence along the best path\n",
    "        \n",
    "        for t in range(self.om.observation_length()+1):\n",
    "            self.V.append([self.NLL_ZERO]*self.f.num_states())\n",
    "            self.B.append([-1]*self.f.num_states())\n",
    "            self.W.append([[] for i in range(self.f.num_states())])  #  multiplying the empty list doesn't make multiple\n",
    "        \n",
    "        # The above code means that self.V[t][j] for t = 0, ... T gives the Viterbi cost\n",
    "        # of state j, time t (in negative log-likelihood form)\n",
    "        # Initialising the costs to NLL_ZERO effectively means zero probability    \n",
    "        \n",
    "        # give the WFST start state a probability of 1.0   (NLL = 0.0)\n",
    "        self.V[0][self.f.start()] = 0.0\n",
    "        \n",
    "        # some WFSTs might have arcs with epsilon on the input (you might have already created \n",
    "        # examples of these in earlier labs) these correspond to non-emitting states, \n",
    "        # which means that we need to process them without stepping forward in time.  \n",
    "        # Don't worry too much about this!  \n",
    "        self.traverse_epsilon_arcs(0)        \n",
    "        \n",
    "    def traverse_epsilon_arcs(self, t):\n",
    "        \"\"\"Traverse arcs with <eps> on the input at time t\n",
    "        \n",
    "        These correspond to transitions that don't emit an observation\n",
    "        \n",
    "        We've implemented this function for you as it's slightly trickier than\n",
    "        the normal case.  You might like to look at it to see what's going on, but\n",
    "        don't worry if you can't fully follow it.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        states_to_traverse = list(self.f.states()) # traverse all states\n",
    "        while states_to_traverse:\n",
    "            \n",
    "            # Set i to the ID of the current state, the first \n",
    "            # item in the list (and remove it from the list)\n",
    "            i = states_to_traverse.pop(0)   \n",
    "        \n",
    "            # don't bother traversing states which have zero probability\n",
    "            if self.V[t][i] == self.NLL_ZERO:\n",
    "                    continue\n",
    "        \n",
    "            for arc in f.arcs(i):\n",
    "                \n",
    "                if arc.ilabel == 0:     # if <eps> transition\n",
    "                  \n",
    "                    j = arc.nextstate   # ID of next state  \n",
    "                \n",
    "                    if self.V[t][j] > self.V[t][i] + float(arc.weight):\n",
    "                        \n",
    "                        # this means we've found a lower-cost path to\n",
    "                        # state j at time t.  We might need to add it\n",
    "                        # back to the processing queue.\n",
    "                        self.V[t][j] = self.V[t][i] + float(arc.weight)\n",
    "                        \n",
    "                        # save backtrace information.  In the case of an epsilon transition, \n",
    "                        # we save the identity of the best state at t-1.  This means we may not\n",
    "                        # be able to fully recover the best path, but to do otherwise would\n",
    "                        # require a more complicated way of storing backtrace information\n",
    "                        self.B[t][j] = self.B[t][i] \n",
    "                        \n",
    "                        # and save the output labels encountered - this is a list, because\n",
    "                        # there could be multiple output labels (in the case of <eps> arcs)\n",
    "                        if arc.olabel != 0:\n",
    "                            self.W[t][j] = self.W[t][i] + [arc.olabel] \n",
    "                        \n",
    "                        if j not in states_to_traverse:\n",
    "                            states_to_traverse.append(j)\n",
    "\n",
    "    \n",
    "    def forward_step(self, t):\n",
    "          \n",
    "        for i in self.f.states():\n",
    "            \n",
    "            if not self.V[t-1][i] == self.NLL_ZERO:   # no point in propagating states with zero probability\n",
    "                \n",
    "                for arc in self.f.arcs(i):\n",
    "                    \n",
    "                    if arc.ilabel != 0: # <eps> transitions don't emit and observation\n",
    "                        j = arc.nextstate\n",
    "                        tp = float(arc.weight)  # transition prob\n",
    "                        ep = -self.om.log_observation_probability(self.f.input_symbols().find(arc.ilabel), t)  # emission negative log prob\n",
    "                        prob = tp + ep + self.V[t-1][i] # they're logs\n",
    "                        if prob < self.V[t][j]:\n",
    "                            self.V[t][j] = prob\n",
    "                            self.B[t][j] = i\n",
    "                            \n",
    "                            # store the output labels encountered too\n",
    "                            if arc.olabel !=0:\n",
    "                                self.W[t][j] = [arc.olabel]\n",
    "                            \n",
    "    \n",
    "    def finalise_decoding(self):\n",
    "        \"\"\" this incorporates the probability of terminating at each state\n",
    "        \"\"\"\n",
    "        \n",
    "        for state in self.f.states():\n",
    "            final_weight = float(self.f.final(state))\n",
    "            if self.V[-1][state] != self.NLL_ZERO:\n",
    "                if final_weight == math.inf:\n",
    "                    self.V[-1][state] = self.NLL_ZERO  # effectively says that we can't end in this state\n",
    "                else:\n",
    "                    self.V[-1][state] += final_weight\n",
    "                    \n",
    "        # get a list of all states where there was a path ending with non-zero probability\n",
    "        finished = [x for x in self.V[-1] if x < self.NLL_ZERO]\n",
    "        if not finished:  # if empty\n",
    "            print(\"No path got to the end of the observations.\")\n",
    "        \n",
    "        \n",
    "    def decode(self):\n",
    "        self.initialise_decoding()\n",
    "        t = 1\n",
    "        while t <= self.om.observation_length():\n",
    "            self.forward_step(t)\n",
    "            self.traverse_epsilon_arcs(t)\n",
    "            t += 1\n",
    "        self.finalise_decoding()\n",
    "    \n",
    "    def backtrace(self):\n",
    "        \n",
    "        best_final_state = self.V[-1].index(min(self.V[-1])) # argmin\n",
    "        best_state_sequence = [best_final_state]\n",
    "        best_out_sequence = []\n",
    "        \n",
    "        t = self.om.observation_length()   # ie T\n",
    "        j = best_final_state\n",
    "        while t >= 0:\n",
    "            i = self.B[t][j]\n",
    "            best_state_sequence.append(i)\n",
    "            best_out_sequence = self.W[t][j] + best_out_sequence  # computer scientists might like\n",
    "                                                                                # to make this more efficient!\n",
    "            # continue the backtrace at state i, time t-1\n",
    "            j = i  \n",
    "            t-=1\n",
    "            \n",
    "        best_state_sequence.reverse()\n",
    "        \n",
    "        # convert the best output sequence from FST integer labels into strings\n",
    "        best_out_sequence = ' '.join([ self.f.output_symbols().find(label) for label in best_out_sequence])\n",
    "        \n",
    "        return (best_state_sequence, best_out_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wfst():\n",
    "    f = generate_multiple_words_wfst([k for k in lex.keys()])\n",
    "    f.set_input_symbols(state_table)\n",
    "    f.set_output_symbols(phone_table)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = create_wfst()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 0, 242) 17\n",
      "(4, 0, 66) 4\n",
      "(6, 0, 86) 6\n",
      "(3, 0, 29) 3\n",
      "(9, 0, 102) 9\n",
      "(5, 0, 113) 5\n",
      "(17, 0, 186) 17\n",
      "(8, 0, 134) 8\n",
      "(6, 0, 52) 6\n",
      "(4, 0, 42) 4\n",
      "(6, 0, 82) 6\n",
      "(6, 0, 62) 6\n",
      "(17, 0, 245) 17\n",
      "(17, 0, 190) 17\n",
      "(17, 0, 250) 17\n",
      "(5, 0, 46) 5\n",
      "(6, 0, 42) 6\n",
      "(18, 0, 233) 18\n",
      "(5, 0, 62) 5\n",
      "(5, 0, 23) 5\n",
      "(5, 0, 98) 5\n",
      "(3, 0, 31) 3\n",
      "(4, 0, 45) 4\n",
      "(5, 0, 49) 5\n",
      "(5, 0, 69) 5\n",
      "(5, 0, 28) 5\n",
      "(3, 0, 27) 3\n",
      "(3, 0, 33) 3\n",
      "(17, 0, 226) 17\n",
      "(7, 0, 79) 7\n",
      "(17, 0, 167) 17\n",
      "(4, 0, 34) 4\n",
      "(5, 0, 82) 5\n",
      "(6, 0, 43) 6\n",
      "(17, 0, 258) 17\n",
      "(4, 0, 40) 4\n",
      "(6, 0, 83) 6\n",
      "(7, 0, 50) 7\n",
      "(17, 0, 175) 17\n",
      "(4, 0, 34) 4\n",
      "(4, 0, 50) 4\n",
      "(6, 0, 78) 6\n",
      "(7, 0, 77) 7\n",
      "(10, 0, 96) 10\n",
      "(6, 0, 70) 6\n",
      "(3, 0, 28) 3\n",
      "(17, 0, 220) 17\n",
      "(6, 0, 80) 6\n",
      "(17, 0, 248) 17\n",
      "(3, 0, 54) 3\n",
      "(17, 0, 208) 17\n"
     ]
    }
   ],
   "source": [
    "def read_transcription(wav_file):\n",
    "    \"\"\"\n",
    "    Get the transcription corresponding to wav_file.\n",
    "    \"\"\"\n",
    "    \n",
    "    transcription_file = os.path.splitext(wav_file)[0] + '.txt'\n",
    "    \n",
    "    with open(transcription_file, 'r') as f:\n",
    "        transcription = f.readline().strip()\n",
    "    \n",
    "    return transcription\n",
    "\n",
    "\n",
    "f = create_wfst()\n",
    "decoder = MyViterbiDecoder(f, '')\n",
    "\n",
    "for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):\n",
    "    \n",
    "    decoder.om.load_audio(wav_file)\n",
    "    \n",
    "    decoder.decode()\n",
    "    (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "                                               # to return the words along the best path\n",
    "    \n",
    "    transcription = read_transcription(wav_file)\n",
    "    error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "    word_count = len(transcription.split())\n",
    "    \n",
    "    print(error_counts, word_count)     # you'll need to accumulate these to produce an overall Word Error Rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Initial systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glob.glob('/group/teaching/asr/labs/recordings/*.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function states:\n",
      "\n",
      "states(...) method of pywrapfst._MutableFst instance\n",
      "    states(self)\n",
      "    \n",
      "    Returns an iterator over all states in the FST.\n",
      "    \n",
      "    Returns:\n",
      "      A StateIterator object for the FST.\n",
      "    \n",
      "    See also: `arcs`, `mutable_arcs`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(f.states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 213)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_states_arcs (f):\n",
    "    '''\n",
    "    Count the number of states and arcs in an wfst\n",
    "    type f pywrapfst\n",
    "    para f the wfst to count the number of states and arcs for\n",
    "    '''\n",
    "    num_states = 0\n",
    "    num_arcs = 0\n",
    "    \n",
    "    for state in f.states():\n",
    "        num_states += 1\n",
    "\n",
    "        for arc in f.arcs(state):\n",
    "            num_arcs += 1\n",
    "\n",
    "            \n",
    "    return num_states,num_arcs\n",
    "            \n",
    "count_state_arcs(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No path got to the end of the observations.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MyViterbiDecoder' object has no attribute 'forward_counter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-e3d4931ad644>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \"\"\".format(time_cost,num_states,num_arcs,tot_errors,tot_words))     # you'll need to accumulate these to produce an overall Word Error Rate\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mrun_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-e3d4931ad644>\u001b[0m in \u001b[0;36mrun_exp\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# save the forward computation counter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mcomputation_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_counter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# save the number states and arcs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MyViterbiDecoder' object has no attribute 'forward_counter'"
     ]
    }
   ],
   "source": [
    "def run_exp():\n",
    "    '''\n",
    "    Run a test on the test data, record the WER, speed and memory cost.\n",
    "    '''\n",
    "    f = create_wfst()\n",
    "    decoder = MyViterbiDecoder(f, '')\n",
    "    \n",
    "    # store the error counts and word counts\n",
    "    tot_errors,tot_words = 0,0\n",
    "    \n",
    "    for wav_file in glob.glob('/group/teaching/asr/labs/recordings/*.wav'):\n",
    "    \n",
    "        decoder.om.load_audio(wav_file)\n",
    "        \n",
    "        # start a timer\n",
    "        start = time.time()\n",
    "        \n",
    "        decoder.decode()\n",
    "        (state_path, words) = decoder.backtrace()  # you'll need to modify the backtrace() from Lab 4\n",
    "                                                   # to return the words along the best path\n",
    "        # stop the timer\n",
    "        end = time.time()\n",
    "        time_cost = end - start\n",
    "        \n",
    "        # save the forward computation counter\n",
    "        computation_counter = decoder.forward_counter\n",
    "        \n",
    "        # save the number states and arcs\n",
    "        num_states,num_arcs = count_states_arcs(f)\n",
    "        \n",
    "        transcription = read_transcription(wav_file)\n",
    "        error_counts = wer.compute_alignment_errors(transcription, words)\n",
    "        word_count = len(transcription.split())\n",
    "        \n",
    "        # increase the total error and word count\n",
    "        tot_errors += error_counts\n",
    "        tot_words += word_count\n",
    "\n",
    "        print(\"\"\"\n",
    "        Run time: {}, \n",
    "        Number of forward computations: {},\n",
    "        Number of states and arcs: {} {},\n",
    "        Number of errors {} in {} words\n",
    "        \"\"\".format(time_cost,num_states,num_arcs,tot_errors,tot_words))     # you'll need to accumulate these to produce an overall Word Error Rate\n",
    "\n",
    "run_exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hi\n",
      "mu23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a=23\n",
    "print(\"\"\"\n",
    "hi\n",
    "mu{}\n",
    "\"\"\".format(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall WER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speed (time/ the number of forward computations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### memory (the number of states and arcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task2 - System tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task3 - Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "class Baum_Welch:\n",
    "    \n",
    "    NLL_ZERO = 0  # define a constant representing -log(0).  This is really infinite, but approximate\n",
    "                     # it here with a very large number\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __init__(self, f, audio_file_name):\n",
    "        \"\"\"Set up the decoder class with an audio file and WFST f\n",
    "        \"\"\"\n",
    "        self.om = observation_model.ObservationModel()\n",
    "        self.f = f\n",
    "        \n",
    "        self.mapping = {}\n",
    "        \n",
    "        if audio_file_name:\n",
    "            self.om.load_audio(audio_file_name)\n",
    "        else:\n",
    "            self.om.load_dummy_audio()\n",
    "        \n",
    "        self.initialise_decoding()\n",
    "    \n",
    "    def initialise_decoding(self):\n",
    "        \"\"\"set up the values for V_j(0) (as negative log-likelihoods)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.A = []\n",
    "        for t in range(self.om.observation_length()+1):\n",
    "            self.A.append([self.NLL_ZERO]*self.f.num_states())\n",
    "        \n",
    "        self.B = []\n",
    "        for t in range(self.om.observation_length()+1):\n",
    "            self.B.append([self.NLL_ZERO]*self.f.num_states())\n",
    "        \n",
    "        # The above code means that self.V[t][j] for t = 0, ... T gives the Viterbi cost\n",
    "        # of state j, time t (in negative log-likelihood form)\n",
    "        # Initialising the costs to NLL_ZERO effectively means zero probability    \n",
    "        \n",
    "        # give the WFST start state a probability of 1.0   (NLL = 0.0)\n",
    "        self.A[0][f.start()] = 1\n",
    "        \n",
    "        # some WFSTs might have arcs with epsilon on the input (you might have already created \n",
    "        # examples of these in earlier labs) these correspond to non-emitting states, \n",
    "        # which means that we need to process them without stepping forward in time.  \n",
    "        # Don't worry too much about this!  \n",
    "        self.traverse_epsilon_arcs(0)\n",
    "        \n",
    "    def traverse_epsilon_arcs(self, t):\n",
    "        \"\"\"Traverse arcs with <eps> on the input at time t\n",
    "        \n",
    "        These correspond to transitions that don't emit an observation\n",
    "        \n",
    "        We've implemented this function for you as it's slightly trickier than\n",
    "        the normal case.  You might like to look at it to see what's going on, but\n",
    "        don't worry if you can't fully follow it.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        states_to_traverse = list(range(self.f.num_states())) # traverse all states\n",
    "        while states_to_traverse:\n",
    "            \n",
    "            # Set i to the ID of the current state, the first \n",
    "            # item in the list (and remove it from the list)\n",
    "            i = states_to_traverse.pop(0)   \n",
    "        \n",
    "            # don't bother traversing states which have zero probability\n",
    "            #if self.A[t][i] == self.NLL_ZERO:\n",
    "             #       continue\n",
    "        \n",
    "            for arc in self.f.arcs(i):\n",
    "                \n",
    "                if arc.ilabel == 0:     # if <eps> transition\n",
    "                  \n",
    "                    j = arc.nextstate   # ID of next state  \n",
    "                \n",
    "                    self.A[t][j] += self.A[t][i]*math.exp(-float(arc.weight))\n",
    "                   \n",
    "                    if j not in states_to_traverse:\n",
    "                            states_to_traverse.append(j)\n",
    "\n",
    "    \n",
    "    def forward_step(self, t):\n",
    "        \n",
    "        \n",
    "        states_to_traverse = list(range(self.f.num_states())) # traverse all states\n",
    "        while states_to_traverse:\n",
    "            \n",
    "            # Set i to the ID of the current state, the first \n",
    "            # item in the list (and remove it from the list)\n",
    "            i = states_to_traverse.pop(0)\n",
    "\n",
    "            for arc in self.f.arcs(i):\n",
    "                if arc.ilabel != 0:\n",
    "                    \n",
    "                        j = arc.nextstate   # ID of next state  \n",
    "                        \n",
    "                        \n",
    "                        # this means we've found a lower-cost path to\n",
    "                        # state j at time t.  We might need to add it\n",
    "                        # back to the processing queue.\n",
    "                        self.A[t][j] += self.A[t-1][i]*math.exp(-float(arc.weight))* math.exp(self.om.log_observation_probability(\n",
    "                        state_table.find(arc.ilabel),t))\n",
    "                    \n",
    "                \n",
    "\n",
    "    \n",
    "    def finalise_decoding(self):\n",
    "        self.P = 0\n",
    "        states_to_transverse = list(range(self.f.num_states()))\n",
    "        while states_to_transverse:\n",
    "            \n",
    "            i = states_to_transverse.pop(0)\n",
    "            for arc in self.f.arcs(i):\n",
    "                if arc.ilabel != 0 and arc.nextstate==f.num_states()-1:\n",
    "                    j = arc.nextstate   # ID of next state  \n",
    "                    \n",
    "                \n",
    "                    # this means we've found a lower-cost path to\n",
    "                    # state j at time t.  We might need to add it\n",
    "                    # back to the processing queue.\n",
    "                    \n",
    "                    self.P += self.A[self.om.observation_length()][i]*math.exp(-float(arc.weight))\n",
    "                    self.B[self.om.observation_length()][i] = math.exp(-float(arc.weight))\n",
    "            \n",
    "        #self.P = -math.log(self.P)\n",
    "        \n",
    "                \n",
    "    def forward(self):\n",
    "        \n",
    "        self.initialise_decoding()\n",
    "        t = 1\n",
    "        while t <= self.om.observation_length():\n",
    "            self.forward_step(t)\n",
    "            t+=1\n",
    "        self.finalise_decoding()\n",
    "        print (self.mapping)\n",
    "        t = self.om.observation_length()-1\n",
    "        print (self.om.observation_length())\n",
    "        while t>=0:\n",
    "            self.back_pass(t)\n",
    "            t-=1\n",
    "        self.BP = sum[self.B[0][0]]\n",
    "            \n",
    "    \n",
    "    def back_pass(self,t):\n",
    "        states_to_traverse = list(range(self.f.num_states())) # traverse all states\n",
    "        while states_to_traverse:\n",
    "            \n",
    "            # Set i to the ID of the current state, the first \n",
    "            # item in the list (and remove it from the list)\n",
    "            i = states_to_traverse.pop(0)\n",
    "\n",
    "            for arc in self.f.arcs(i):\n",
    "                if arc.ilabel != 0:\n",
    "                    \n",
    "                    j = arc.nextstate   # ID of next state  \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    # this means we've found a lower-cost path to\n",
    "                    # state j at time t.  We might need to add it\n",
    "                    # back to the processing queue.\n",
    "                    self.B[t][i] += self.B[t+1][j]*math.exp(-float(arc.weight))* math.exp(self.om.log_observation_probability(\n",
    "                    state_table.find(arc.ilabel),t+1))\n",
    "    \n",
    "\n",
    "    def forward_backward(self,n):\n",
    "        while n > 0:\n",
    "            \n",
    "            states_to_traverse = list(range(self.f.num_states()))[:-1] # traverse all states\n",
    "            while states_to_traverse:\n",
    "                \n",
    "                i = states_to_traverse.pop(0)\n",
    "                \n",
    "                for arc in self.f.arcs(i):\n",
    "                    \n",
    "                    if arc.ilabel != 0:\n",
    "                    \n",
    "                        j = arc.nextstate\n",
    "                        try:\n",
    "                            arc_occupation = sum([self.A[t][i]*math.exp(-float(arc.weight))*math.exp(self.om.log_observation_probability(\n",
    "                                state_table.find(arc.ilabel),t+1))*self.B[t+1][j] for t in range(1,self.om.observation_length())])\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                            total_arc = sum([self.A[t][i]*math.exp(-float(arc.weight))*math.exp(self.om.log_observation_probability(\n",
    "                                state_table.find(arc.ilabel),t+1))*self.B[t+1][j] for arc in self.f.arcs(i) for t in range(1,self.om.observation_length())])\n",
    "                        except KeyError:\n",
    "                            pass\n",
    "                        try:\n",
    "                            f.add_arc(i,fst.Arc(arc.ilabel, arc.olabel, fst.Weight(\"log\",-math.log(arc_occupation/total_arc)), j))\n",
    "                            print(-math.log(arc_occupation/total_arc))\n",
    "                        except ZeroDivisionError:\n",
    "                            pass\n",
    "            \n",
    "            \n",
    "            n -= 1\n",
    "        \n",
    "\n",
    "re_est = Baum_Welch(f, '')   # empty string '' just means use dummy probabilities for testing\n",
    "re_est.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3025851178914483\n",
      "0.20067069043237284\n",
      "2.3025851178914483\n",
      "0.20067069043237257\n",
      "2.302585117891448\n",
      "0.20067069043237326\n",
      "2.302585117891448\n",
      "0.2006706904323727\n",
      "2.3025851178914483\n",
      "0.20067069043237284\n",
      "2.302585117891448\n",
      "0.2006706904323734\n",
      "2.3025851178914483\n",
      "0.20067069043237257\n",
      "2.302585117891448\n",
      "0.20067069043237246\n",
      "2.302585117891448\n",
      "0.20067069043237298\n",
      "2.3025851178914483\n",
      "0.20067069043237284\n",
      "2.302585117891448\n",
      "0.2006706904323727\n",
      "2.3025851178914483\n",
      "2.9539628879328794\n",
      "0.7835537014756919\n",
      "3.1892799331336854\n",
      "1.1041986838148938\n",
      "2.95396288793288\n",
      "0.7835537014756916\n",
      "3.189279933133686\n",
      "1.1041986838148936\n",
      "2.9539628879328794\n",
      "0.7835537014756921\n",
      "3.1892799331336854\n",
      "1.1041986838148945\n",
      "2.9539628879328794\n",
      "0.7835537014756918\n",
      "3.189279933133686\n",
      "1.104198683814894\n",
      "2.95396288793288\n",
      "0.7835537014756919\n",
      "3.1892799331336854\n",
      "1.1041986838148943\n",
      "2.95396288793288\n",
      "0.7835537014756921\n",
      "3.189279933133686\n",
      "1.1041986838148947\n",
      "2.95396288793288\n",
      "0.7835537014756917\n",
      "3.189279933133686\n",
      "1.104198683814894\n",
      "2.9539628879328794\n",
      "0.7835537014756916\n",
      "3.189279933133686\n",
      "1.104198683814894\n",
      "2.9539628879328794\n",
      "0.7835537014756919\n",
      "3.1892799331336845\n",
      "1.1041986838148943\n",
      "2.9539628879328794\n",
      "0.7835537014756917\n",
      "3.1892799331336854\n",
      "1.1041986838148943\n",
      "2.95396288793288\n",
      "0.7835537014756915\n",
      "3.189279933133686\n",
      "1.1041986838148943\n",
      "2.3978952954323725\n",
      "2.4773020682406246\n",
      "3.3321232104540086\n",
      "1.147575093831203\n",
      "3.450906192746976\n",
      "1.3590011059767155\n",
      "4.189878686938025\n",
      "2.0238615167677607\n",
      "4.467103897482353\n",
      "2.3852164170991337\n",
      "3.332123210454009\n",
      "1.1475750938312028\n",
      "3.450906192746976\n",
      "1.3590011059767149\n",
      "4.189878686938025\n",
      "2.0238615167677603\n",
      "4.467103897482353\n",
      "2.3852164170991332\n",
      "3.332123210454009\n",
      "1.1475750938312035\n",
      "3.450906192746976\n",
      "1.3590011059767155\n",
      "4.189878686938025\n",
      "2.023861516767761\n",
      "4.467103897482353\n",
      "2.385216417099134\n",
      "3.3321232104540095\n",
      "1.1475750938312022\n",
      "3.4509061927469764\n",
      "1.3590011059767146\n",
      "4.189878686938025\n",
      "2.0238615167677603\n",
      "4.467103897482353\n",
      "2.3852164170991332\n",
      "3.3321232104540086\n",
      "1.147575093831203\n",
      "3.4509061927469755\n",
      "1.359001105976716\n",
      "4.189878686938024\n",
      "2.023861516767761\n",
      "4.467103897482353\n",
      "2.385216417099134\n",
      "3.332123210454009\n",
      "1.1475750938312037\n",
      "3.4509061927469764\n",
      "1.359001105976716\n",
      "4.189878686938025\n",
      "2.023861516767761\n",
      "4.467103897482353\n",
      "2.385216417099134\n",
      "3.332123210454009\n",
      "1.1475750938312026\n",
      "3.450906192746976\n",
      "1.3590011059767149\n",
      "4.189878686938025\n",
      "2.0238615167677607\n",
      "4.467103897482353\n",
      "2.385216417099134\n",
      "3.3321232104540086\n",
      "1.147575093831203\n",
      "3.450906192746976\n",
      "1.359001105976715\n",
      "4.189878686938025\n",
      "2.02386151676776\n",
      "4.467103897482353\n",
      "2.3852164170991332\n",
      "3.332123210454008\n",
      "1.1475750938312035\n",
      "3.4509061927469746\n",
      "1.3590011059767158\n",
      "4.189878686938024\n",
      "2.0238615167677607\n",
      "4.467103897482352\n",
      "2.3852164170991337\n",
      "3.3321232104540086\n",
      "1.147575093831203\n",
      "3.450906192746976\n",
      "1.3590011059767155\n",
      "4.189878686938024\n",
      "2.023861516767761\n",
      "4.467103897482352\n",
      "2.385216417099134\n",
      "3.332123210454009\n",
      "1.147575093831203\n",
      "3.4509061927469764\n",
      "1.3590011059767155\n",
      "4.189878686938025\n",
      "2.023861516767761\n",
      "4.467103897482353\n",
      "2.385216417099134\n",
      "2.5454360344603484\n",
      "2.6051440153688183\n",
      "2.7536167403045293\n",
      "2.876686687027065\n"
     ]
    }
   ],
   "source": [
    "re_est.forward_backward(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task4 - Advanced topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.79690938805287"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-math.log(re_est.P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
